{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fd729a",
   "metadata": {},
   "source": [
    "# Φάση 1: Σύστημα Ανάκτησης Πληροφορίας\n",
    "\n",
    ">Ανθίππη Φατσέα | p3190209\n",
    "\n",
    "### Στόχος και Αντικείμενο\n",
    "Στο πλαίσιο της παρούσας προγραμματιστικής εργασίας, ζητείται η ανάπτυξη, βελτιστοποίηση και αξιολόγηση ενός συστήματος Ανάκτησης Πληροφορίας (IR) με χρήση της μηχανής **Elasticsearch**. Το αντικείμενο μελέτης περιλαμβάνει μια συλλογή εγγράφων ερευνητικών έργων και ένα σύνολο ερωτημάτων φυσικής γλώσσας.\n",
    "\n",
    "Κύριος στόχος είναι η επίτευξη υψηλής **ακρίβειας (Precision)** στα πρώτα αποτελέσματα και υψηλής **ανάκλησης (Recall)** στο σύνολο. Η αξιολόγηση της απόδοσης πραγματοποιείται βάσει των μετρικών **MAP**, **Precision@k** και **Recall@k**, όπως ορίζονται στις προδιαγραφές.\n",
    "\n",
    "### Τεχνολογικό Υπόβαθρο\n",
    "Τεχνολογικά, η υλοποίηση βασίζεται στον αλγόριθμο **BM25**, ένα πιθανοτικό μοντέλο κατάταξης που αποτελεί το standard στη βιομηχανία για αναζήτηση κειμένου. Το σύστημα ενισχύθηκε με τεχνικές Επεξεργασίας Φυσικής Γλώσσας (NLP), όπως **stemming** (αποκοπή καταλήξεων), **lemmatization** (λήμματα) και διαχείριση **συνωνύμων**, με σκοπό τη βελτιστοποίηση της **λεξιλογικής ταύτισης (Lexical Matching)**.\n",
    "\n",
    "### Μεθοδολογική Προσέγγιση: Στρατηγική Πλεονασμού\n",
    "Λαμβάνοντας υπόψη τον περιορισμένο όγκο της συλλογής δεδομένων, υιοθετήθηκε μια στρατηγική **σκόπιμου πλεονασμού** κατά τον σχεδιασμό του ευρετηρίου. Συγκεκριμένα, η πληροφορία κάθε εγγράφου αποθηκεύεται σε πολλαπλά πεδία με διαφορετικές μορφές (Raw Text, Stems, Lemmas, Synonyms).\n",
    "\n",
    "Η επιλογή αυτή έγινε συνειδητά για δύο λόγους:\n",
    "1.  **Αντιστάθμιση Σπανιότητας Δεδομένων (Data Sparsity):** Μειώνεται ο κίνδυνος επιστροφής μηδενικών αποτελεσμάτων σε αυστηρές αναζητήσεις (π.χ. λόγω διαφορετικής γραμματικής κλίσης), εξασφαλίζοντας υψηλότερη Ανάκληση.\n",
    "2.  **Ευελιξία Πειραματισμού:** Επιτρέπει τον συνδυασμό διαφορετικών βαρών (boosting) ανά πεδίο, ώστε να βρεθεί η χρυσή τομή μεταξύ της αυστηρής ταύτισης και της ευρείας αναζήτησης.\n",
    "\n",
    "### Πειραματική Διαδικασία και Αξιολόγηση\n",
    "Η τελική αρχιτεκτονική διαμορφώθηκε κατόπιν πειραματισμού (**Ablation Study**), όπου αξιολογήθηκαν διάφορες στρατηγικές ευρετηρίασης. Συγκεκριμένα, εξετάστηκαν οι εξής παράμετροι:\n",
    "\n",
    "* **N-grams (Bigrams):** Υλοποιήθηκε η ευρετηρίαση διγραμμάτων (token bigrams) για τον εντοπισμό εννοιών δύο λέξεων. Ωστόσο, η συγκριτική ανάλυση έδειξε ότι η **Φραστική Αναζήτηση (Phrase Matching)** κάλυπτε αποδοτικότερα την ανάγκη εντοπισμού διαδοχικών λέξεων, προσφέροντας υψηλότερη ακρίβεια χωρίς τον θόρυβο που εισήγαγαν τα bigrams. Ως εκ τούτου, η βαρύτητα των bigrams στο τελικό query μειώθηκε/μηδενίστηκε.\n",
    "* **Διαχωρισμός Τίτλων (Title Extraction):** Δοκιμάστηκε η απόσπαση των τίτλων από το κυρίως κείμενο μέσω ευρετικών κανόνων. Η τεχνική αυτή δεν επέφερε βελτίωση στα αποτελέσματα, πιθανώς λόγω της ανομοιογένειας στη δομή των εγγράφων, και ως εκ τούτου δεν συμμετέχει ενεργά στην τελική εξίσωση κατάταξης.\n",
    "\n",
    "Το τελικό μοντέλο εστιάζει στον βέλτιστο συνδυασμό **Phrase Matching** (για υψηλό Precision) και **Synonym/Stem Matching** (για υψηλό Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas elasticsearch nltk matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc16dc8",
   "metadata": {},
   "source": [
    "### Εισαγωγή Βιβλιοθηκών και Αρχικοποίηση\n",
    "Στο ακόλουθο κελί εισάγονται οι απαραίτητες βιβλιοθήκες Python (pandas, elasticsearch, nltk, sklearn). Επιπλέον, ορίζονται οι διαδρομές των αρχείων δεδομένων (έγγραφα, ερωτήματα, σχετικότητες) και του εκτελέσιμου αρχείου αξιολόγησης (trec_eval), καθώς και η σύνδεση με τον εξυπηρετητή Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f422ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "import subprocess\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "try:\n",
    "    from sklearn.metrics import precision_recall_curve, auc\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "    nltk.data.find('corpora/omw-1.4')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "file_docs = '../data/documents.csv'\n",
    "file_queries = '../data/queries.csv'\n",
    "qrels_file = \"../data/qrels.txt\"\n",
    "trec_eval_path = \"../../trec_eval/trec_eval.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b661a",
   "metadata": {},
   "source": [
    "### Προεπεξεργασία Κειμένου και Γλωσσική Ανάλυση\n",
    "\n",
    "Για τη βελτιστοποίηση του ευρετηρίου, προηγήθηκε στατιστική ανάλυση του κειμενικού σώματος (corpus analysis) μέσω βοηθητικών Python scripts. Η ανάλυση αυτή ανέδειξε συγκεκριμένα μοτίβα \"θορύβου\":\n",
    "\n",
    "1.  **Ανάλυση Συχνότητας Μεμονωμένων Λέξεων:**\n",
    "    * Υπολογίστηκε η συχνότητα εμφάνισης όλων των λέξεων στο corpus (αφού αφαιρέθηκαν τα κοινά αγγλικά stopwords).\n",
    "    * **Εύρημα:** Λέξεις όπως *\"project\"*, *\"research\"*, *\"aim\"*, *\"proposal\"* εμφανίζονταν σε ποσοστό άνω του 90% των εγγράφων.\n",
    "    * **Απόφαση:** Οι λέξεις αυτές εντάχθηκαν στη λίστα `safe_noise`. Επειδή υπάρχουν παντού, ο δείκτης IDF (Inverse Document Frequency) τους είναι σχεδόν μηδενικός, οπότε η αφαίρεσή τους μειώνει το μέγεθος του ευρετηρίου χωρίς να βλάπτει την ανάκτηση.\n",
    "\n",
    "2.  **Ανάλυση Επαναλαμβανόμενων Φράσεων:**\n",
    "    Η διαδικασία εντοπισμού τυποποιημένων εκφράσεων υλοποιήθηκε σε δύο στάδια, συνδυάζοντας την εμπειρική παρατήρηση με τη στατιστική επαλήθευση:\n",
    "\n",
    "    * **Φάση Α - Ποιοτική Επισκόπηση & Έρευνα Πεδίου:**\n",
    "        Αρχικά, διαβάσαμε δειγματοληπτικά ορισμένα έγγραφα και εντοπίσαμε πολλά τυποποιημένα κείμενα. Ελέγχοντας τους κανονισμούς των ευρωπαϊκών προγραμμάτων (π.χ. Horizon 2020), επιβεβαιώσαμε ότι πρόκειται για υποχρεωτικές νομικές φράσεις που δεν έχουν σχέση με την ίδια την έρευνα.\n",
    "\n",
    "    * **Φάση Β - Στατιστική Επαλήθευση (Corpus Statistics):**\n",
    "        Για την ακριβή οριοθέτηση αυτών των φράσεων, αναπτύχθηκε κώδικας στατιστικής ανάλυσης. Χρησιμοποιώντας τον `CountVectorizer` του `sklearn`, αναζητήθηκαν n-grams μεταβλητού μήκους (**3 έως 6 λέξεων**) με ευρεία διασπορά (εμφάνιση σε τουλάχιστον **10 έγγραφα**).\n",
    "        \n",
    "        Για την αποφυγή πλεονασμών, εφαρμόστηκε αλγόριθμος φιλτραρίσματος που προκρίνει τις μακροσκελέστερες φράσεις. Συγκεκριμένα, εάν εντοπιστεί μια φράση (π.χ. *\"funded by the european union\"*) η οποία αποτελεί υποσύνολο μιας μεγαλύτερης που έχει ήδη καταγραφεί (π.χ. *\"this project is funded by the european union\"*), τότε η μικρότερη αγνοείται.\n",
    "\n",
    "    * **Αποτέλεσμα & Απόφαση:**\n",
    "        Δημιουργήθηκε μια \"καθαρή\" λίστα τυποποιημένων εκφράσεων (`boilerplate_phrases`) χωρίς επικαλύψεις. Η αφαίρεσή τους κρίθηκε απαραίτητη, καθώς η παρουσία τους αλλοιώνει τη θεματική ομοιότητα (π.χ. αποτρέπει τη συσχέτιση δύο άσχετων έργων μόνο και μόνο επειδή μοιράζονται την ίδια νομική ρήτρα χρηματοδότησης).\n",
    "  \n",
    "Η συνάρτηση προεπεξεργασίας αφαιρεί αυτά τα στοιχεία, εκτελεί tokenization και παράγει πολλαπλές μορφές των όρων (λήμματα, ρίζες και διγράμματα) για την ενίσχυση της αναζήτησης.\n",
    "\n",
    "1.  **Μηχανισμός Εξαγωγής Τίτλων (Title Extraction):**\n",
    "    Καθώς τα δεδομένα δεν διαθέτουν διακριτό πεδίο τίτλου, αναπτύχθηκε ένας ευρετικός αλγόριθμος (heuristic) εντοπισμού τίτλων. Παρατηρήθηκε ότι πολλά έγγραφα ακολουθούν τη δομή *\"Τίτλος Έργου: Περιγραφή...\"*. Ο αλγόριθμος εντοπίζει την πρώτη εμφάνιση της άνω-κάτω τελείας (`:`) και, εφόσον το τμήμα που προηγείται έχει λογικό μήκος (3-30 λέξεις), το εξάγει ως **Τίτλο**. Αυτό το πεδίο αποθηκεύεται ξεχωριστά (`title_extracted`) για να ενισχύσει τη σχετικότητα σε ερωτήματα που αναζητούν συγκεκριμένα ονόματα έργων.\n",
    "\n",
    "\n",
    "Ορίζεται η διαδικασία προεπεξεργασίας (preprocessing pipeline) που εφαρμόζεται τόσο στα έγγραφα όσο και στα ερωτήματα. Η διαδικασία περιλαμβάνει:\n",
    "* **Καθαρισμό:** Αφαίρεση ειδικών χαρακτήρων, σημείων στίξης και τυποποιημένων φράσεων (boilerplate phrases) που δεν προσφέρουν πληροφοριακή αξία.\n",
    "* **Tokenization:** Διαχωρισμός του κειμένου σε λέξεις.\n",
    "* **Αφαίρεση Stopwords:** Χρήση της λίστας του NLTK εμπλουτισμένης με ειδικές λέξεις θορύβου για το συγκεκριμένο πεδίο γνώσης.\n",
    "* **Λημματοποίηση (Lemmatization):** Αναγωγή στη γραμματική ρίζα (π.χ. \"better\" -> \"good\"). Βελτιώνει την ακρίβεια της σημασίας.\n",
    "* **Θεματική Ανάλυση (Stemming):** Αποκοπή καταλήξεων (π.χ. \"batteries\" -> \"batteri\"). Αυξάνει την Ανάκληση (Recall).\n",
    "* **Παραγωγή Διγραμμάτων (Bigrams):** Δημιουργία ζευγών λέξεων για την ενίσχυση του σημασιολογικού πλαισίου.\n",
    "* **Εξαγωγή Τίτλου:** Υλοποίηση μηχανισμού εντοπισμού τίτλου βάσει στίξης (χρησιμοποιείται πειραματικά).\n",
    "\n",
    "\n",
    "Για τη βελτιστοποίηση του ευρετηρίου, δεν χρησιμοποιήθηκαν έτοιμες generic λίστες, αλλά προηγήθηκε **στατιστική ανάλυση του κειμενικού σώματος**. Μέσω βοηθητικών script σε Python, σαρώθηκαν τα κείμενα για τον εντοπισμό \"θορύβου\" που είναι ειδικός για το συγκεκριμένο domain (ευρωπαϊκά ερευνητικά έργα)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e289e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stops = set(stopwords.words('english'))\n",
    "safe_noise = {\n",
    "    \"project\", \"aim\", \"proposal\", \"consortium\", \"summary\", \n",
    "    \"objective\", \"work\", \"package\", \"action\", \"activities\",\n",
    "    \"main\", \"specific\", \"within\", \"during\", \"result\", \"presented\",\n",
    "    \"paper\", \"study\", \"report\", \"deliverable\", \"task\", \"partners\",\n",
    "    \"the\", \"and\", \"of\", \"in\", \"to\", \"a\", \"is\", \"for\", \"on\", \"that\"\n",
    "}\n",
    "\n",
    "full_stopwords_list = nltk_stops.union(safe_noise)\n",
    "\n",
    "boilerplate_phrases = [\n",
    "\n",
    "    \"the main objective of this project\", \"the aim of this project\",\n",
    "    \"this project aims to\", \"this proposal aims to\", \"the goal of this proposal\",\n",
    "    \"in this project\", \"in this proposal\", \"the proposed research\",\n",
    "    \"to achieve this goal\", \"the overall objective\",\n",
    "    \"aim of this project is to\", \"goal of this project is to\",\n",
    "    \"objective of this project is to\", \"the aim of this project is\",\n",
    "    \"objective of the project is to\", \"the goal of this project is\",\n",
    "    \"goal of this proposal is to\", \"aim of the project is to\",\n",
    "    \"aim of this proposal is to\", \"objective of this proposal is to\",\n",
    "    \"the objective of this project is\", \"goal of the project is to\",\n",
    "    \"the aim of this proposal is\", \"the aim of the project is\",\n",
    "    \"the goal of this proposal is\", \"the objective of this proposal is\",\n",
    "    \"main objective of this project is\", \"main objective of the project is\",\n",
    "    \"the main objective of the project\", \"overall objective of the project is\",\n",
    "    \"the overall objective of the project\", \"the main goal of this project\",\n",
    "    \"state of the art\", \"the current state of the art\", \n",
    "    \"beyond the state of the art\", \"the state of the art in\",\n",
    "    \"advance the state of the art\", \"of the state of the art\",\n",
    "    \"beyond the current state of the\", \"will use state of the art\",\n",
    "    \"will be carried out\", \"proof of concept\", \"feasibility study\",\n",
    "    \"feasibility study of a\", \"understanding the role of\", \n",
    "    \"elucidating the role of\", \"at the end of the project\",\n",
    "    \"will be carried out\", \"there is an urgent need to\",\n",
    "    \"is one of the most important\", \"development of a new\",\n",
    "    \"development of a novel\", \"development of an innovative\",\n",
    "    \"research and innovation\", \"european union\", \"horizon 2020\", \"h2020\", \"fp7\",\n",
    "    \"grant agreement\", \"the beneficiaries of the sme instrument\",\n",
    "    \"establishing services enhancing the innovation management\",\n",
    "    \"enhancing the innovation management capacity of\",\n",
    "    \"the innovation management capacity of smes\",\n",
    "    \"services enhancing the innovation management capacity\",\n",
    "    \"innovation management capacity of smes in\",\n",
    "    \"significant innovation activities and high potential\",\n",
    "    \"smes with significant innovation activities and\",\n",
    "    \"with significant innovation activities and high\",\n",
    "    \"innovation activities and high potential for\",\n",
    "    \"enhance the innovation management capacity of\"\n",
    "]\n",
    "\n",
    "boilerplate_phrases.sort(key=len, reverse=True)\n",
    "\n",
    "def analyze_and_clean_safe(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    \n",
    "    text = re.sub(r'\\\\[nrtfv]', ' ', text)\n",
    "    text = html.unescape(text)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    for phrase in boilerplate_phrases:\n",
    "        text = re.sub(re.escape(phrase), \" \", text, flags=re.IGNORECASE)\n",
    "            \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s:]', ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "def extract_title(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    if ':' in text:\n",
    "        parts = text.split(':', 1)\n",
    "        potential_title = parts[0].strip()\n",
    "        if 3 <= len(potential_title.split()) <= 30:\n",
    "            return potential_title\n",
    "    return \"\"\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def apply_nlp(clean_text):\n",
    "    if not clean_text: \n",
    "        return {'lemma': '', 'stem': '', 'bigrams': ''}\n",
    "    \n",
    "    text_no_punct = clean_text.replace(':', ' ')\n",
    "    tokens = word_tokenize(text_no_punct)\n",
    "    \n",
    "    filtered = [w for w in tokens if w not in full_stopwords_list and len(w) > 1]\n",
    "    \n",
    "    lemmas = [lemmatizer.lemmatize(w) for w in filtered]\n",
    "    stems = [stemmer.stem(w) for w in filtered]\n",
    "    \n",
    "    bi_grams = list(ngrams(filtered, 2))\n",
    "    bigrams_list = [\"_\".join(bg) for bg in bi_grams]\n",
    "    \n",
    "    return {\n",
    "        'lemma': \" \".join(lemmas),\n",
    "        'stem': \" \".join(stems),\n",
    "        'bigrams': \" \".join(bigrams_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf5a1b",
   "metadata": {},
   "source": [
    "### Φόρτωση και Επεξεργασία Δεδομένων\n",
    "Πραγματοποιείται η ανάγνωση των αρχείων εγγράφων (`documents.csv`) και ερωτημάτων (`queries.csv`). Στη συνέχεια, εφαρμόζονται οι συναρτήσεις προεπεξεργασίας σε κάθε εγγραφή. Για κάθε κείμενο δημιουργούνται πολλαπλές αναπαραστάσεις (καθαρό κείμενο, λήμματα, θέματα, διγράμματα), οι οποίες θα χρησιμοποιηθούν ως ξεχωριστά πεδία στο ευρετήριο για την υποστήριξη της υβριδικής αναζήτησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & Process Data\n",
    "df_docs = pd.read_csv(file_docs, header=None, names=['ID', 'Text'], dtype=str)\n",
    "df_docs = df_docs[df_docs['ID'].str.lower() != 'id'].dropna(subset=['Text'])\n",
    "\n",
    "df_docs['temp_text'] = df_docs['Text'].apply(analyze_and_clean_safe)\n",
    "df_docs['extracted_title'] = df_docs['temp_text'].apply(extract_title)\n",
    "\n",
    "nlp_docs = df_docs['temp_text'].apply(apply_nlp)\n",
    "\n",
    "df_docs['clean_text'] = df_docs['temp_text'].apply(lambda x: x.replace(':', ''))\n",
    "df_docs['lemmatized_text'] = nlp_docs.apply(lambda x: x['lemma'])\n",
    "df_docs['stemmed_text'] = nlp_docs.apply(lambda x: x['stem'])\n",
    "df_docs['bigrams_text'] = nlp_docs.apply(lambda x: x['bigrams'])\n",
    "\n",
    "# Load & Process Queries\n",
    "df_queries = pd.read_csv(file_queries, header=None, names=['ID', 'Text'], dtype=str)\n",
    "df_queries = df_queries[df_queries['ID'].str.lower() != 'id'].dropna(subset=['Text'])\n",
    "\n",
    "df_queries['temp_text'] = df_queries['Text'].apply(analyze_and_clean_safe)\n",
    "nlp_queries = df_queries['temp_text'].apply(apply_nlp)\n",
    "\n",
    "df_queries['clean_text'] = df_queries['temp_text'].apply(lambda x: x.replace(':', ''))\n",
    "df_queries['lemmatized_text'] = nlp_queries.apply(lambda x: x['lemma'])\n",
    "df_queries['stemmed_text'] = nlp_queries.apply(lambda x: x['stem'])\n",
    "df_queries['bigrams_text'] = nlp_queries.apply(lambda x: x['bigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5921ced",
   "metadata": {},
   "source": [
    "### 3. Παραμετροποίηση Ευρετηρίου Elasticsearch\n",
    "\n",
    "Στο στάδιο αυτό καθορίζεται η αρχιτεκτονική του ευρετηρίου (Index Configuration), η οποία αποτελεί τον πυρήνα του συστήματος ανάκτησης. Η παραμετροποίηση εστιάζει στη διαχείριση της σημασιολογικής συσχέτισης μέσω συνωνύμων, στη βελτιστοποίηση του αλγορίθμου κατάταξης και στον ορισμό εξειδικευμένων αναλυτών.\n",
    "\n",
    "#### Διαχείριση Συνωνύμων (Synonym Expansion)\n",
    "Για την αντιμετώπιση του προβλήματος της αναντιστοιχίας λεξιλογίου (vocabulary mismatch), όπου το ερώτημα του χρήστη διαφέρει μορφολογικά από τους όρους του εγγράφου, ορίστηκε το φίλτρο `my_synonyms`.\n",
    "Αυτή η τεχνική αυξάνει την Ανάκληση (Recall), καθώς επιτρέπει την ανάκτηση εγγράφων που αναφέρονται στην ίδια έννοια με διαφορετική ορολογία.\n",
    "\n",
    "#### Ορισμός Αναλυτών\n",
    "Δημιουργήθηκαν τρεις διακριτοί αναλυτές για να εξυπηρετήσουν διαφορετικές ανάγκες αναζήτησης:\n",
    "1.  **`synonym_analyzer`:** Ενσωματώνει τα συνώνυμα, αφαίρεση stopwords και stemming. Χρησιμοποιείται στο βασικό πεδίο κειμένου για μέγιστη ανάκληση.\n",
    "2.  **`exact_analyzer`:** Εφαρμόζει stemming και αφαίρεση stopwords, αλλά **όχι** συνώνυμα. Χρησιμοποιείται για να προσδώσει υψηλότερη βαρύτητα (Precision) σε έγγραφα που περιέχουν τους ακριβείς όρους του ερωτήματος.\n",
    "3.  **`python_analyzer`:** Ένας απλός whitespace tokenizer που μετατρέπει σε πεζά γράμματα. Χρησιμοποιείται για τα πεδία που έχουν ήδη υποστεί επεξεργασία από την Python (λήμματα, ρίζες, διγράμματα).\n",
    "\n",
    "#### Ρύθμιση Αλγορίθμου BM25\n",
    "Εκτελέστηκε ειδικός αλγόριθμος βελτιστοποίησης για τον εντοπισμό των ιδανικών παραμέτρων:\n",
    "* **`k1 = 2.0`:** Αυξάνει τον κορεσμό της συχνότητας όρων (Term Frequency saturation), δίνοντας μεγαλύτερη έμφαση στην επανάληψη λέξεων εντός του κειμένου.\n",
    "* **`b = 1.0`:** Επιβάλλει πλήρη κανονικοποίηση βάσει μήκους (Full Length Normalization), ώστε να μην ευνοούνται τα μακροσκελή έγγραφα έναντι των συντομότερων.\n",
    "\n",
    "#### Mappings\n",
    "Κάθε έγγραφο ευρετηριάζεται σε πολλαπλά πεδία (`text`, `text.exact`, `text_lemmatized`, `text_stemmed`, `text_bigrams`, `title_extracted`), επιτρέποντας την εφαρμογή Υβριδικής Αναζήτησης όπου κάθε πεδίο συμμετέχει με διαφορετικό βάρος στο τελικό σκορ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95606666",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list_for_set = list(full_stopwords_list) \n",
    "\n",
    "index_name = \"ir_phase1_showcase\"\n",
    "\n",
    "settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1, \"number_of_replicas\": 0,\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"my_custom_stop\": { \n",
    "                    \"type\": \"stop\", \n",
    "                    \"stopwords\": stopwords_list_for_set\n",
    "                },\n",
    "                \"my_length_filter\": { \"type\": \"length\", \"min\": 2 },\n",
    "                \"my_synonyms\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"uk, united kingdom, great britain\", \"eu, european union, europe\",\n",
    "                        \"usa, united states, america\", \"erc, european research council\",\n",
    "                        \"h2020, horizon 2020\", \"fp7, framework programme 7\",\n",
    "                        \"sme, smes, small medium enterprise, startup\",\n",
    "                        \"res, renewable energy sources, renewables\", \"pv, photovoltaic, solar, solar energy\",\n",
    "                        \"wind, wind energy, wind power, wind farm\", \"co2, carbon dioxide, greenhouse gas, ghg\",\n",
    "                        \"climate, climate change, global warming\", \"ai, artificial intelligence, machine learning, ml, deep learning\",\n",
    "                        \"ict, information communication technology\", \"iot, internet of things\",\n",
    "                        \"big data, data analytics\", \"cloud, cloud computing\", \"5g, fifth generation\",\n",
    "                        \"cancer, tumor, tumour, oncology\", \"hiv, aids\", \"dna, rna, genomics, genetic\",\n",
    "                        \"pharma, pharmaceutical, drug, medicine\", \"agri, agriculture, agricultural, farming\",\n",
    "                        \"food, agri food, agrifood\"\n",
    "                    ]\n",
    "                },\n",
    "                \"my_stemmer\": { \"type\": \"stemmer\", \"language\": \"english\" }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"synonym_analyzer\": {\n",
    "                    \"type\": \"custom\", \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\", \"my_synonyms\", \"my_length_filter\", \"my_custom_stop\", \"my_stemmer\"]\n",
    "                },\n",
    "                \"exact_analyzer\": {\n",
    "                    \"type\": \"custom\", \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\", \"my_length_filter\", \"my_custom_stop\", \"my_stemmer\"]\n",
    "                },\n",
    "                \"python_analyzer\": {\n",
    "                    \"type\": \"custom\", \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"index\": { \"similarity\": { \"default\": { \"type\": \"BM25\", \"b\": 1.0, \"k1\": 2.0 } } }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": { \n",
    "                \"type\": \"text\", \"analyzer\": \"synonym_analyzer\",\n",
    "                \"fields\": { \"exact\": { \"type\": \"text\", \"analyzer\": \"exact_analyzer\" } }\n",
    "            },\n",
    "            \"text_lemmatized\": { \"type\": \"text\", \"analyzer\": \"python_analyzer\" },\n",
    "            \"text_stemmed\": { \"type\": \"text\", \"analyzer\": \"python_analyzer\" },\n",
    "            \"text_bigrams\": { \"type\": \"text\", \"analyzer\": \"python_analyzer\" },\n",
    "            \"title_extracted\": { \"type\": \"text\", \"analyzer\": \"synonym_analyzer\", \"similarity\": \"BM25\" }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if es.indices.exists(index=index_name): es.indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, body=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ec24e",
   "metadata": {},
   "source": [
    "### Επισκόπηση Ροής Επεξεργασίας Κειμένου\n",
    "\n",
    "Η παρακάτω συνάρτηση, `view_processing_pipeline`, δημιουργήθηκε για να επιθεωρήσουμε οπτικά την ποιότητα των δεδομένων σε κάθε στάδιο της προεπεξεργασίας. Λαμβάνει τυχαία δείγματα από το DataFrame και εμφανίζει τη σταδιακή μεταμόρφωση του κειμένου:\n",
    "\n",
    "1.  **[ORIGINAL]:** Το ακατέργαστο κείμενο όπως ανακτήθηκε από το αρχείο `.csv`.\n",
    "2.  **[CLEANED]:** Το κείμενο μετά από μετατροπή σε πεζά (lowercase), αφαίρεση σημείων στίξης, αριθμών και περιττών κενών.\n",
    "3.  **[LEMMATIZED]:** Το κείμενο μετά την εφαρμογή Λημματοποίησης (Lemmatization), όπου οι λέξεις επιστρέφουν στη λεξικολογική τους βάση (π.χ. \"better\" -> \"good\", \"running\" -> \"run\"), και αφαίρεση των Stopwords.\n",
    "4.  **[STEMMED]:** Το κείμενο μετά την εφαρμογή Stemming (Porter Stemmer), όπου αφαιρούνται οι καταλήξεις για να μείνει η ρίζα (π.χ. \"simulation\" -> \"simul\").\n",
    "5.  **[BIGRAMS]:** Ζεύγη διαδοχικών λημμάτων (n-grams, n=2) που βοηθούν στην αποτύπωση φράσεων (π.χ. \"artificial_intelligence\").\n",
    "\n",
    "Η οπτικοποίηση αυτή είναι κρίσιμη για τον εντοπισμό λαθών (π.χ. αν κολλάνε λέξεις μεταξύ τους ή αν σβήνονται χρήσιμοι όροι)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_processing_pipeline(df, num_samples=10):\n",
    "\n",
    "    subset = df.sample(min(num_samples, len(df)))\n",
    "\n",
    "    for i, row in subset.iterrows():\n",
    "        doc_id = row['ID']\n",
    "        title = row.get('extracted_title', '-')\n",
    "        \n",
    "        step1_orig = row['Text']\n",
    "        step2_clean = row.get('clean_text', '')\n",
    "        step3_lemma = row.get('lemmatized_text', '')\n",
    "        step4_stem  = row.get('stemmed_text', '')\n",
    "        step5_bi    = row.get('bigrams_text', '')\n",
    "\n",
    "        print(f\"DOC ID: {doc_id} | Title: {title}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        print(\" [ORIGINAL]:\")\n",
    "        print(textwrap.fill(step1_orig[:200] + \"...\", width=100, initial_indent='    ', subsequent_indent='    '))\n",
    "        \n",
    "        print(\"\\n [CLEANED]:\")\n",
    "        print(textwrap.fill(step2_clean[:200] + \"...\", width=100, initial_indent='    ', subsequent_indent='    '))\n",
    "\n",
    "        print(\"\\n [LEMMATIZED]:\")\n",
    "        print(textwrap.fill(step3_lemma[:200] + \"...\", width=100, initial_indent='    ', subsequent_indent='    '))\n",
    "\n",
    "        print(\"\\n [STEMMED]:\")\n",
    "        print(textwrap.fill(step4_stem[:200] + \"...\", width=100, initial_indent='    ', subsequent_indent='    '))\n",
    "        \n",
    "        if step5_bi:\n",
    "            print(\"\\n [BIGRAMS]:\")\n",
    "            print(textwrap.fill(step5_bi[:200] + \"...\", width=100, initial_indent='    ', subsequent_indent='    '))\n",
    "\n",
    "        print(f\"{'='*100}\\n\")\n",
    "\n",
    "view_processing_pipeline(df_docs, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e83c9a",
   "metadata": {},
   "source": [
    "### Ευρετηρίαση Εγγράφων\n",
    "Εκτελείται η διαδικασία μαζικής εισαγωγής των επεξεργασμένων εγγράφων στο Elasticsearch. Το σύστημα αποθηκεύει τα έγγραφα μαζί με όλα τα μεταδεδομένα που παρήχθησαν κατά το στάδιο της προεπεξεργασίας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52475a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk(es, ({\n",
    "    \"_index\": index_name,\n",
    "    \"_source\": { \n",
    "        \"ID\": row['ID'], \n",
    "        \"text\": row['clean_text'],\n",
    "        \"text_lemmatized\": row['lemmatized_text'],\n",
    "        \"text_stemmed\": row['stemmed_text'],\n",
    "        \"text_bigrams\": row['bigrams_text'],\n",
    "        \"title_extracted\": row['extracted_title']\n",
    "    }\n",
    "} for _, row in df_docs.iterrows()))\n",
    "es.indices.refresh(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b86a1ec",
   "metadata": {},
   "source": [
    "### Αξιολόγηση με \"Δίκαιες\" Μετρικές\n",
    "\n",
    "Στην κλασική αξιολόγηση, το `k` (πλήθος αποτελεσμάτων) είναι σταθερό, γεγονός που μπορεί να αδικηθεί το σύστημα σε δύο περιπτώσεις:\n",
    "1.  **Όταν $k < \\text{Σωστά Έγγραφα}$:** Το Recall \"τιμωρείται\" επειδή δεν χωράνε όλα τα σωστά στα αποτελέσματα.\n",
    "2.  **Όταν $k > \\text{Σωστά Έγγραφα}$:** Το Precision \"τιμωρείται\" επειδή αναγκαστικά υπάρχουν κενές θέσεις.\n",
    "\n",
    "Για να έχουμε μια πιο δίκαιη εικόνα της απόδοσης στο συγκεκριμένο \"παράθυρο\" αποτελεσμάτων, χρησιμοποιούμε τις **Bounded Metrics**.\n",
    "\n",
    "#### 1. Ορισμός του Εφικτού Στόχου (Effective K)\n",
    "Ορίζουμε ως παρονομαστή το μέγιστο δυνατό αριθμό σωστών εγγράφων που θα *μπορούσε* θεωρητικά να βρει το σύστημα:\n",
    "\n",
    "$$\\text{Effective K} = \\min(k, \\text{Total Known})$$\n",
    "\n",
    "#### 2. Οι Μετρικές (Bounded Recall & Precision)\n",
    "Και οι δύο μετρικές προσαρμόζονται στο `Effective K`. Σε αυτή την προσέγγιση, **οι τιμές τους ταυτίζονται**, καθώς απαντούν στην ίδια ερώτηση: *\"Πόσο καλά τα πήγε το σύστημα σε σχέση με το βέλτιστο δυνατό που επέτρεπε το k;\"*\n",
    "\n",
    "$$\\text{Bounded Metric} = \\frac{\\text{Found Relevant}}{\\text{Effective K}} \\times 100\\%$$\n",
    "\n",
    "\n",
    "> Αν έχουμε 10 σωστά έγγραφα και ζητήσουμε $k=5$ (Effective K = 5), και το σύστημα βρει 5:\n",
    "Τότε παίρνει **100%**, διότι γέμισε όλο το διαθέσιμο χώρο με σωστά αποτελέσματα (παρόλο που άφησε 5 απέξω)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qrels(file_path):\n",
    "    qrels = {}\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 4:\n",
    "                    qid = parts[0]\n",
    "                    doc_id = parts[2]\n",
    "                    relevance = int(parts[3])\n",
    "                    if relevance > 0:\n",
    "                        if qid not in qrels: qrels[qid] = set()\n",
    "                        qrels[qid].add(doc_id)\n",
    "        return qrels\n",
    "    except FileNotFoundError:\n",
    "        print(\" Qrels file not found.\")\n",
    "        return {}\n",
    "\n",
    "def run_search_evaluation(df_queries, es_client, index_name, qrels_file_path, top_k=20, num_queries=10):\n",
    "    qrels = load_qrels(qrels_file_path)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ΕΚΤΕΛΕΣΗ ΑΝΑΖΗΤΗΣΗΣ & ΑΞΙΟΛΟΓΗΣΗ (TOP {top_k})\")\n",
    "    print(f\"Recall & Precision προσαρμοσμένα στο 'εφικτό' (Bounded Metrics)\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "    subset = df_queries.head(num_queries)\n",
    "    summary_stats = []\n",
    "    \n",
    "    total_known = 0\n",
    "    total_found = 0\n",
    "\n",
    "    for i, row in subset.iterrows():\n",
    "        q_id = str(row['ID'])\n",
    "        q_text = row['Text']\n",
    "        q_clean = row['clean_text']\n",
    "        \n",
    "        true_relevant_docs = qrels.get(q_id, set())\n",
    "        num_known = len(true_relevant_docs)\n",
    "\n",
    "        search_body = {\n",
    "            \"size\": top_k,\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": q_clean,\n",
    "                    \"fields\": [\"text^3\", \"text_lemmatized\", \"text_stemmed\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"tie_breaker\": 0.3\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = es_client.search(index=index_name, body=search_body)\n",
    "        hits = response['hits']['hits']\n",
    "\n",
    "        print(f\"QUERY ID: {q_id} (Πρέπει να βρει: {num_known} έγγραφα)\")\n",
    "        print(f\"Text: \\\"{q_text[:80]}...\\\"\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        found_relevant_cnt = 0\n",
    "        \n",
    "        for rank, hit in enumerate(hits, 1):\n",
    "            doc_source = hit['_source']\n",
    "            doc_id = str(doc_source.get('ID', hit['_id']))\n",
    "            doc_title = doc_source.get('title_extracted', 'No Title')[:60]\n",
    "            \n",
    "            is_match = doc_id in true_relevant_docs\n",
    "            \n",
    "            if is_match:\n",
    "                status = \"MATCH!\"\n",
    "                color = \"\\033[92m\" \n",
    "                found_relevant_cnt += 1\n",
    "            else:\n",
    "                status = \"No... \"\n",
    "                color = \"\\033[91m\" \n",
    "            \n",
    "            reset = \"\\033[0m\"\n",
    "            print(f\"   {rank}. {color}{status}{reset} DOC: {doc_id} | {doc_title}...\")\n",
    "\n",
    "\n",
    "        effective_k = min(top_k, num_known)\n",
    "        \n",
    "        if effective_k > 0:\n",
    "\n",
    "            adj_recall = (found_relevant_cnt / effective_k * 100)\n",
    "            adj_precision = (found_relevant_cnt / effective_k * 100)\n",
    "            adj_recall = min(adj_recall, 100.0)\n",
    "            adj_precision = min(adj_precision, 100.0)\n",
    "        else:\n",
    "            adj_recall = 0.0\n",
    "            adj_precision = 0.0\n",
    "\n",
    "        print(f\"\\nΑποτέλεσμα: Βρέθηκαν {found_relevant_cnt} από τα {num_known}.\")\n",
    "        print(f\"Bounded Recall (στο k={top_k}):    {adj_recall:.1f}%\")\n",
    "        print(f\"Bounded Precision (στο k={top_k}): {adj_precision:.1f}%\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'QID': q_id,\n",
    "            'Known': num_known,\n",
    "            'Found': found_relevant_cnt,\n",
    "            'Recall': adj_recall,\n",
    "            'Precision': adj_precision\n",
    "        })\n",
    "        \n",
    "        total_known += num_known\n",
    "        total_found += found_relevant_cnt\n",
    "\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ΣΥΓΚΕΝΤΡΩΤΙΚΟΣ ΠΙΝΑΚΑΣ (BOUNDED METRICS @ k={top_k})\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"{'QUERY':<6} | {'KNOWN':<6} | {'FOUND':<6} | {'BOUND. RECALL':<15} | {'BOUND. PRECISION':<18}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for stat in summary_stats:\n",
    "        print(f\"{stat['QID']:<6} | {stat['Known']:<6} | {stat['Found']:<6} | {stat['Recall']:<15.1f} | {stat['Precision']:<18.1f}\")\n",
    "    \n",
    "    print(\"-\" * 75)\n",
    "    print(f\"ΣΥΝΟΛΟ: Βρέθηκαν {total_found} από τα {total_known} σχετικα κείμενα.\")\n",
    "    print(f\"ACTUAL GLOBAL RECALL: {(total_found/total_known)*100:.2f}%\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "\n",
    "run_search_evaluation(df_queries, es, index_name, qrels_file, top_k=5, num_queries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17eaef",
   "metadata": {},
   "source": [
    "### Διαδικασία Αναζήτησης και Αξιολόγησης\n",
    "\n",
    "Ο κώδικας εκτελεί τη διαδικασία ανάκτησης για τρία διαφορετικά σενάρια αποτελεσμάτων ($k \\in \\{20, 30, 50\\}$). Η στρατηγική αναζήτησης βασίζεται σε ένα **Υβριδικό Ερώτημα (Hybrid Boolean Query)**, το οποίο συνδυάζει πολλαπλά πεδία με διαφορετικά βάρη (boosts).\n",
    "\n",
    "#### Ανάλυση Στρατηγικής και Βαρών \n",
    "Η λογική απόδοσης βαρών σχεδιάστηκε ώστε να εξισορροπεί την Ανάκληση (Recall) με την Ακρίβεια (Precision):\n",
    "\n",
    "* **Phrase Ranking (Boost 10.0 & 2.0):**\n",
    "    * `match_phrase` με `slop: 0` (**Boost 10.0**): Αποτελεί τον ισχυρότερο παράγοντα κατάταξης. Αναζητά τις λέξεις του ερωτήματος **ακριβώς με τη σειρά** που δόθηκαν, χωρίς να παρεμβάλλονται άλλες λέξεις. Αν βρεθεί η ακριβής φράση, το έγγραφο θεωρείται εξαιρετικά σχετικό.\n",
    "    * `match_phrase` με `slop: 2` (**Boost 2.0**): Επιτρέπει μικρή απόσταση (έως 2 λέξεις) μεταξύ των όρων, καλύπτοντας περιπτώσεις όπου παρεμβάλλεται ένα άρθρο ή επίθετο (π.χ. \"solar *thermal* energy\").\n",
    "\n",
    "* **Precision - Exact Match (Boost 5.0):**\n",
    "    * Το πεδίο `text.exact` αναζητά τους όρους όπως ακριβώς γράφτηκαν (χωρίς συνώνυμα). Του δίνεται υψηλή προτεραιότητα (5.0) γιατί η ύπαρξη της ακριβούς λέξης είναι πιο σημαντική από την ύπαρξη της ρίζας της.\n",
    "\n",
    "* **Base Recall & Meaning (Boost 1.0 - 1.5):**\n",
    "    * Τα πεδία `text`, `text_stemmed` (Boost 1.0) και `text_lemmatized` (Boost 1.5) λειτουργούν ως \"δίχτυ ασφαλείας\". Εξασφαλίζουν ότι θα ανακτηθούν έγγραφα ακόμα και αν οι λέξεις εμφανίζονται με διαφορετική κατάληξη ή μορφή, μεγιστοποιώντας την Ανάκληση.\n",
    "\n",
    "#### Απενεργοποίηση Πεδίων \n",
    "Στον κώδικα παρατηρούνται δύο πεδία με μηδενικό βάρος (`boost: 0.0`). Αυτό αποτελεί συνειδητή επιλογή προκύπτουσα από πειραματική αξιολόγηση:\n",
    "\n",
    "* **`text_bigrams` (Boost 0.0):** Παρόλο που τα διγράμματα (bigrams) εντοπίζουν έννοιες δύο λέξεων (π.χ. \"climate_change\"), τα πειράματα έδειξαν ότι η χρήση του ισχυρού `match_phrase` (Boost 10.0) κάλυπτε ήδη αυτή την ανάγκη αποδοτικότερα. Η ταυτόχρονη χρήση τους προκαλούσε θόρυβο στα αποτελέσματα, οπότε απενεργοποιήθηκαν για το τελικό μοντέλο.\n",
    "* **`title_extracted` (Boost 0.0):** Η ευρετική μέθοδος εξαγωγής τίτλων αποδείχθηκε ασταθής λόγω της ανομοιογένειας στη δομή των εγγράφων. Η ενεργοποίησή της μείωνε ελαφρώς το MAP, επομένως αφαιρέθηκε από την τελική εξίσωση κατάταξης.\n",
    "\n",
    "#### Σύγκριση Match Phrase vs. N-grams\n",
    "Η επιλογή να δοθεί έμφαση στο `match_phrase` έναντι των `ngrams` (bigrams) βασίζεται στις θεμελιώδεις διαφορές τους:\n",
    "\n",
    "* **Match Phrase:** Είναι δυναμικός έλεγχος. Το σύστημα ελέγχει τις **θέσεις (positions)** των λέξεων στο έγγραφο κατά την αναζήτηση. Εξασφαλίζει ότι η λέξη Α είναι δίπλα στη λέξη Β. Είναι πιο ακριβές για ερωτήματα φυσικής γλώσσας.\n",
    "* **Bigrams (N-grams):** Είναι στατικός έλεγχος. Το ζεύγος \"solar energy\" αποθηκεύεται ως μία ενιαία \"λέξη\" (`solar_energy`) στο λεξιλόγιο. Αν και χρήσιμο για σταθερές ορολογίες, είναι λιγότερο ευέλικτο από το phrase matching και αυξάνει το μέγεθος του ευρετηρίου. Στη συγκεκριμένη υλοποίηση, το `match_phrase` αποδείχθηκε ανώτερο στην ανάκτηση σχετικών εγγράφων.\n",
    "\n",
    "### Σχολιασμός Αποτελεσμάτων και Συμπεράσματα\n",
    "\n",
    "Τα πειραματικά αποτελέσματα για $k=50$ επιδεικνύουν την υψηλή απόδοση του Υβριδικού Μοντέλου Αναζήτησης, επιτυγχάνοντας **(MAP) 0.8123**. Η ανάλυση των επιμέρους μετρικών οδηγεί στα εξής συμπεράσματα:\n",
    "\n",
    "* **Εξαιρετική Ακρίβεια Κορυφής:**\n",
    "    Η τιμή **Precision@5** αγγίζει το **0.9400**, γεγονός που υποδηλώνει ότι στα 5 πρώτα αποτελέσματα, σχεδόν και τα 5 είναι απολύτως σχετικά με το ερώτημα. Αυτό οφείλεται κυρίως στην υψηλή βαρύτητα (Boost 10.0) που δόθηκε στο `match_phrase`, το οποίο διασφαλίζει ότι οι χρήστες βρίσκουν άμεσα αυτό που ψάχνουν.\n",
    "\n",
    "* **Σχεδόν Τέλεια Ανάκληση :**\n",
    "    Η τιμή **Recall@50** φτάνει το **0.9900**. Αυτό σημαίνει ότι το σύστημα καταφέρνει να ανακτήσει το **99%** όλων των σχετικών εγγράφων που υπάρχουν στη συλλογή για τα δοσμένα ερωτήματα. Η επιτυχία αυτή πιστώνεται στη χρήση Συνωνύμων, Lemmatization και Stemming, τα οποία επέτρεψαν την ανάκτηση εγγράφων ακόμα και με διαφορετική ορολογία.\n",
    "\n",
    "* **Σταθερότητα Κατάταξης:**\n",
    "    Παρατηρούμε ότι καθώς αυξάνεται το $k$ (από 20 σε 50), το MAP βελτιώνεται σταθερά (από 0.74 σε 0.81), ενώ η Ακρίβεια (P@5) παραμένει σταθερή στο μέγιστο επίπεδο. Αυτό δείχνει ότι ο αλγόριθμος κατάταξης (BM25 με τα συγκεκριμένα boosts) είναι στιβαρός και τοποθετεί τα πιο σχετικά έγγραφα σταθερά στην κορυφή της λίστας.\n",
    "\n",
    "Συνοψίζοντας, ο συνδυασμός της ακριβούς φραστικής αναζήτησης με τη σημασιολογική επέκταση (συνώνυμα/ρίζες) δημιούργησε ένα σύστημα που ισορροπεί βέλτιστα μεταξύ Ακρίβειας και Ανάκλησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832cbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scenarios = [20, 30, 50] \n",
    "\n",
    "for k in k_scenarios:\n",
    "    output_file = f\"../results/phase1_results_k{k}.txt\"\n",
    "    run_id = f\"phase1_showcase_k{k}\"\n",
    "    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in df_queries.iterrows():\n",
    "            if not row['clean_text']: continue\n",
    "            \n",
    "            query_body = {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"should\": [\n",
    "                            # Base Recall\n",
    "                            { \"match\": { \"text\": { \"query\": row['clean_text'], \"boost\": 1.0 } } },\n",
    "                            { \"match\": { \"text_stemmed\": { \"query\": row['stemmed_text'], \"boost\": 1.0 } } },\n",
    "                            \n",
    "                            # Meaning\n",
    "                            { \"match\": { \"text_lemmatized\": { \"query\": row['lemmatized_text'], \"boost\": 1.5 } } },\n",
    "                            \n",
    "                            # Context\n",
    "                            { \"match\": { \"text_bigrams\": { \"query\": row['bigrams_text'], \"boost\": 0.0 } } },\n",
    "                            \n",
    "                            # Title Boost \n",
    "                            { \"match\": { \"title_extracted\": { \"query\": row['clean_text'], \"boost\": 0.0 } } },\n",
    "\n",
    "                            # Precision\n",
    "                            { \"match\": { \"text.exact\": { \"query\": row['clean_text'], \"boost\": 5.0 } } },\n",
    "                            \n",
    "                            # Phrase Ranking\n",
    "                            { \"match_phrase\": { \"text.exact\": { \"query\": row['clean_text'], \"slop\": 0, \"boost\": 10.0 } } },\n",
    "                            { \"match_phrase\": { \"text.exact\": { \"query\": row['clean_text'], \"slop\": 2, \"boost\": 2.0 } } }\n",
    "                        ],\n",
    "                        \"minimum_should_match\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"size\": k\n",
    "            }\n",
    "            res = es.search(index=index_name, body=query_body)\n",
    "            \n",
    "            for rank, hit in enumerate(res['hits']['hits']):\n",
    "                f.write(f\"{row['ID']}\\tQ0\\t{hit['_source']['ID']}\\t{rank+1}\\t{hit['_score']:.4f}\\t{run_id}\\n\")\n",
    "\n",
    "    print(f\"Αποτελέσματα για k={k} αποθηκεύτηκαν.\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [trec_eval_path, \"-m\", \"map\", \"-m\", \"P.5,10,15,20\", \"-m\", \"recall.5,10,15,20,50\", qrels_file, output_file]\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        print(res.stdout)\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5fd0a2",
   "metadata": {},
   "source": [
    "### Καμπύλες Ακρίβειας-Ανάκλησης\n",
    "\n",
    "Οι παραγόμενες καμπύλες επιβεβαιώνουν την υψηλή ποιότητα του συστήματος ανάκτησης, όπως αυτή αποτυπώθηκε και στις μετρικές MAP.\n",
    "\n",
    "*  Όλες οι καμπύλες ξεκινούν από πολύ υψηλά επίπεδα στον άξονα Υ (Precision $\\approx$ 0.94), γεγονός που καταδεικνύει ότι τα έγγραφα που κατατάσσονται στις κορυφαίες θέσεις είναι σχεδόν στο σύνολό τους σχετικά. Αυτό οφείλεται στην ισχυρή επίδραση της φραστικής αναζήτησης (Phrase Match).\n",
    "* Παρατηρείται ότι η Ακρίβεια παραμένει υψηλή (>0.80) ακόμη και καθώς αυξάνεται η Ανάκληση (κίνηση προς τα δεξιά στον άξονα Χ). Αυτό σημαίνει ότι το σύστημα δεν εισάγει άμεσα μεγάλο όγκο \"θορύβου\" (μη σχετικών εγγράφων) καθώς προχωράμε χαμηλότερα στη λίστα αποτελεσμάτων.\n",
    "*  Το εμβαδόν κάτω από την καμπύλη είναι υψηλό (άνω του 0.80), προσεγγίζοντας την πάνω δεξιά γωνία του διαγράμματος. Αυτό αποτελεί ένδειξη ενός εύρωστου συστήματος που επιτυγχάνει βέλτιστη ισορροπία μεταξύ της εύρεσης όλων των σχετικών εγγράφων και της αποφυγής λανθασμένων αποτελεσμάτων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20051c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_dict = {}\n",
    "qrels_df = pd.read_csv(qrels_file, sep=r'\\s+', header=None, \n",
    "                       names=['QueryID', 'Iteration', 'DocID', 'Relevance'], \n",
    "                       dtype={'QueryID': str, 'DocID': str})\n",
    "for _, row in qrels_df.iterrows():\n",
    "    if row['Relevance'] > 0:\n",
    "        if row['QueryID'] not in qrels_dict: qrels_dict[row['QueryID']] = set()\n",
    "        qrels_dict[row['QueryID']].add(row['DocID'])\n",
    "\n",
    "for k in k_scenarios:\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    \n",
    "    results_file_path = f\"../results/phase1_results_k{k}.txt\"\n",
    "    \n",
    "    if os.path.exists(results_file_path):\n",
    "        with open(results_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                qid = parts[0]; doc_id = parts[2]; score = float(parts[4])\n",
    "                \n",
    "                is_relevant = 1 if (qid in qrels_dict and doc_id in qrels_dict[qid]) else 0\n",
    "                y_true.append(is_relevant)\n",
    "                y_scores.append(score)\n",
    "        \n",
    "        try:\n",
    "            precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR Curve k={k} (AUC={pr_auc:.2f})')\n",
    "            plt.title(f'Precision-Recall Curve (k={k})', fontsize=14)\n",
    "            plt.xlabel('Recall', fontsize=12)\n",
    "            plt.ylabel('Precision', fontsize=12)\n",
    "            plt.legend(loc=\"lower left\")\n",
    "            plt.grid(True, linestyle='--', alpha=0.5)\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating PR Curve for k={k}: {e}\")\n",
    "    else:\n",
    "        print(f\"Results file for k={k} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2ec3d",
   "metadata": {},
   "source": [
    "### Ανάλυση Κορεσμού Συχνότητας\n",
    "\n",
    "Το παρακάτω διάγραμμα απεικονίζει τη σχέση μεταξύ της συχνότητας εμφάνισης ενός όρου ($tf_{t,d}$) και του βάρους που αποδίδει σε αυτόν ο αλγόριθμος BM25 ($w_{t,d}$).\n",
    "\n",
    "Στον άξονα Χ βλέπουμε πόσες φορές εμφανίζεται η λέξη στο κείμενο και στον άξονα Υ πόσο \"σκορ\" κερδίζει το έγγραφο από αυτή τη λέξη.\n",
    "\n",
    "**Παρατηρήσεις:**\n",
    "* **Φθίνουσα Απόδοση (Diminishing Returns):** Παρατηρούμε ότι η καμπύλη του BM25 (κόκκινη γραμμή) αυξάνεται γρήγορα για τις πρώτες εμφανίσεις της λέξης (tf 1 έως 3), αλλά στη συνέχεια \"κορεζεται\" (γίνεται οριζόντια).\n",
    "* **Η σημασία του $k_1=2.0$:** Η επιλογή της παραμέτρου $k_1=2.0$ (έναντι της προεπιλογής 1.2) επιτρέπει στην καμπύλη να ανέβει ψηλότερα και να κορεστεί πιο αργά. Αυτό σημαίνει ότι το σύστημά μας συνεχίζει να επιβραβεύει την επανάληψη μιας λέξης-κλειδί περισσότερο από ό,τι το προεπιλεγμένο μοντέλο, δίνοντας έμφαση στα πολύ πλούσια σε πληροφορία έγγραφα.\n",
    "* **Σύγκριση με Log-TF:** Σε αντίθεση με το παραδοσιακό λογαριθμικό TF (μπλε γραμμή) που αυξάνεται επ' άπειρον, το BM25 έχει ένα άνω όριο (ασύμπτωτη στο $k_1 + 1$), αποτρέποντας τη στρέβλωση των αποτελεσμάτων από spam επαναλήψεις λέξεων."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac83264",
   "metadata": {},
   "source": [
    "### Ανάλυση Κορεσμού Συχνότητας (TF Saturation)\n",
    "\n",
    "Το παραπάνω διάγραμμα αναδεικνύει τη θεμελιώδη διαφορά του αλγορίθμου BM25 έναντι της παραδοσιακής λογαριθμικής συχνότητας (Log-TF), καθώς και την επίδραση της παραμέτρου $k_1$.\n",
    "\n",
    "1.  **Έλεγχος Κορεσμού (Saturation Control):** Σε αντίθεση με την μπλε διακεκομμένη γραμμή (Standard Log-TF) που αυξάνεται επ' άπειρον, οι καμπύλες του BM25 συγκλίνουν σε ένα ανώτατο όριο (ασύμπτωτη). Αυτό προστατεύει το σύστημα από το να υπερ-βαθμολογεί έγγραφα που επαναλαμβάνουν καταχρηστικά την ίδια λέξη (\"keyword stuffing\").\n",
    "\n",
    "2.  **Η Επιλογή $k_1 = 2.0$ (Κόκκινη Γραμμή):**\n",
    "    * Συγκρίνοντας την κόκκινη γραμμή (η παραμετροποίησή μας) με την γκρι (Default $k_1=1.2$), παρατηρούμε ότι η δική μας καμπύλη κορέζεται **πιο αργά**.\n",
    "    * Το ανώτατο όριο σκορ για έναν όρο αυξάνεται από $2.2$ (στο default) σε $3.0$ (στο δικό μας).\n",
    "    * **Πρακτική Σημασία:** Αυτό σημαίνει ότι το σύστημά μας συνεχίζει να \"επιβραβεύει\" την εμφάνιση μιας λέξης-κλειδί ακόμα και αν έχει ήδη εμφανιστεί 5-10 φορές. Αυτή η συμπεριφορά είναι επιθυμητή σε επιστημονικά κείμενα, όπου η συχνή επανάληψη ενός όρου συνήθως υποδηλώνει ότι το έγγραφο εστιάζει βαθιά στο συγκεκριμένο θέμα, και δεν είναι απλώς μια επιφανειακή αναφορά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.linspace(0, 50, 500)\n",
    "\n",
    "k1_current = 2.0  \n",
    "k1_default = 1.2 \n",
    "\n",
    "bm25_weight_custom = (tf * (k1_current + 1)) / (tf + k1_current)\n",
    "bm25_weight_default = (tf * (k1_default + 1)) / (tf + k1_default)\n",
    "\n",
    "linear_tf = tf \n",
    "log_tf = np.log(1 + tf) \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tf, bm25_weight_custom, label=f'BM25 (k1={k1_current}) - Η επιλογή μας', color='#e74c3c', linewidth=2.5)\n",
    "plt.plot(tf, bm25_weight_default, label=f'BM25 Default (k1={k1_default})', color='gray', linestyle='--')\n",
    "plt.plot(tf, 1 + np.log(tf + 1), label='Standard Log-TF (1+log(tf))', color='blue', linestyle=':', alpha=0.6)\n",
    "\n",
    "plt.title(\"Επίδραση Συχνότητας Όρου στο Βάρος (TF Saturation)\", fontsize=14)\n",
    "plt.xlabel(\"Συχνότητα Όρου στο Έγγραφο ($tf_{t,d}$)\", fontsize=12)\n",
    "plt.ylabel(\"Βάρος Όρου ($w_{t,d}$)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 5.0)\n",
    "\n",
    "plt.axhline(y=k1_current+1, color='#e74c3c', linestyle=':', alpha=0.3)\n",
    "plt.text(15, k1_current+1.1, f'Max Saturation = {k1_current+1}', color='#e74c3c', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
