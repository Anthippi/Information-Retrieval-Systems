{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6d2e66",
   "metadata": {},
   "source": [
    "# Φάση 2: Σημασιολογική ανάκτηση χρησιμοποιώντας Transformers1 και FAISS\n",
    "\n",
    "> **Ανθίππη Φατσέα | p3190209**\n",
    "\n",
    "> **Σαπφώ Αικατερίνη Τσαμουρά | 3210204**\n",
    "\n",
    "## Εισαγωγή\n",
    "Η παρούσα εργασία εστιάζει στην υλοποίηση ενός συστήματος ανάκτησης πληροφορίας που βασίζεται στη **σημασιολογική ομοιότητα** και όχι στην απλή λεκτική αντιστοίχιση. Στόχος είναι η ανάκτηση σχετικών επιστημονικών περιλήψεων από τη βάση δεδομένων, απαντώντας σε σύνθετες τεχνικές ερωτήσεις.\n",
    "\n",
    "Η προσέγγισή μας χρησιμοποιεί **Neural Embeddings**, επιτρέποντας στο σύστημα να \"καταλαβαίνει\" το νόημα, τις συνώνυμες έννοιες και το τεχνικό πλαίσιο.\n",
    "\n",
    "## Αρχιτεκτονική Συστήματος\n",
    "Η ροή εργασιών που υλοποιείται στον κώδικα ακολουθεί τα εξής βήματα:\n",
    "\n",
    "1.  **Προεπεξεργασία:**\n",
    "    * Εφαρμόζεται στρατηγικός καθαρισμός κειμένου.\n",
    "    * **Καινοτομία:** Επιλέχθηκε η διατήρηση σημαντικών συμβόλων (π.χ. `&`, `>`, `%`, `€`) μέσω whitelist regex, καθώς σε τεχνικά κείμενα προσδίδουν κρίσιμη σημασιολογική πληροφορία.\n",
    "\n",
    "2.  **Διανυσματοποίηση:**\n",
    "    * Χρήση ισχυρών προ-εκπαιδευμένων μοντέλων Transformer (SBERT: `all-mpnet-base-v2` ή `all-MiniLM-L6-v2`).\n",
    "    * Τα κείμενα μετατρέπονται σε πυκνά διανύσματα (Dense Vectors) που αποτυπώνουν το νόημά τους σε έναν πολυδιάστατο χώρο.\n",
    "\n",
    "3.  **Ευρετηρίαση & Αναζήτηση:**\n",
    "    * Χρήση της βιβλιοθήκης **FAISS** (Facebook AI Similarity Search) για ταχύτατη αναζήτηση.\n",
    "    * Υπολογισμός ομοιότητας με τη μέθοδο **Cosine Similarity** (μέσω Inner Product σε κανονικοποιημένα διανύσματα).\n",
    "\n",
    "4.  **Αξιολόγηση & Οπτικοποίηση:**\n",
    "    * Ποσοτική αξιολόγηση με το πρότυπο **TREC** και υπολογισμός μετρικών (MAP, Precision@k, Recall).\n",
    "    * Ποιοτικός έλεγχος με οπτικοποίηση του διανυσματικού χώρου μέσω μείωσης διαστάσεων (PCA), ώστε να φανεί η συσταδοποίηση των αποτελεσμάτων γύρω από την ερώτηση.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b8ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.11.0.dev20260116+cu126)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anthi\\appdata\\roaming\\python\\python313\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anthi\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\anthi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7af4ae",
   "metadata": {},
   "source": [
    "Εισάγουμε τις απαραίτητες βιβλιοθήκες και ορίζουμε τις διαδρομές των αρχείων.\n",
    "Επιλέγουμε το Pre-trained μοντέλο που θα μετατρέψει τα κείμενα σε διανύσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b07884a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "DOCS_PATH = \"../data/documents.csv\"\n",
    "QUERIES_PATH = \"../data/queries.csv\"\n",
    "QRELS_PATH = \"../data/qrels.txt\"\n",
    "TREC_EVAL_PATH = \"../../trec_eval/trec_eval.exe\"  \n",
    "RESULTS_DIR = \"../results_phase2\"\n",
    "\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c8a8f",
   "metadata": {},
   "source": [
    "## Προεπεξεργασία και Φόρτωση Δεδομένων\n",
    "\n",
    "Σε αυτό το βήμα ορίζουμε τη συνάρτηση καθαρισμού `clean_for_phase2` και φορτώνουμε τα δεδομένα εγγράφων και ερωτήσεων.\n",
    "\n",
    "**Βασικά σημεία της προεπεξεργασίας:**\n",
    "* **HTML Decoding (`html.unescape`):** Μετατρέπουμε κωδικοποιημένους χαρακτήρες (όπως `&amp;`, `&gt;`) στην κανονική τους μορφή (`&`, `>`). Αυτό είναι κρίσιμο για να διατηρηθεί το νόημα σε εκφράσεις όπως \"R&D\" ή συγκρίσεις τιμών.\n",
    "* **Normalization (`NFKC`):** Κανονικοποιούμε τους χαρακτήρες Unicode για ομοιομορφία.\n",
    "* **Διατήρηση Συμβόλων:** Επιλέξαμε να **μην αφαιρέσουμε** τους ειδικούς χαρακτήρες (μέσω Regex), καθώς σύμβολα όπως τα `%`, `$`, `&` περιέχουν σημαντική σημασιολογική πληροφορία για τεχνικά κείμενα.\n",
    "* **Lowercase:** Μετατροπή όλων σε πεζά για μείωση της πολυπλοκότητας του λεξιλογίου.\n",
    "\n",
    "Τέλος, τα δεδομένα φορτώνονται σε Pandas DataFrames και δημιουργείται η στήλη `clean_text` που θα χρησιμοποιηθεί για την παραγωγή των embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f57f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_phase2(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = html.unescape(text)\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,\\?!:;@%#\\+\\-&<>]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "def load_data():\n",
    "    try:\n",
    "        # Documents\n",
    "        df_docs = pd.read_csv(DOCS_PATH)\n",
    "        df_docs.columns = ['ID', 'Text'] \n",
    "        df_docs['clean_text'] = df_docs['Text'].apply(clean_for_phase2)\n",
    "        \n",
    "        # Queries\n",
    "        df_queries = pd.read_csv(QUERIES_PATH)\n",
    "        df_queries.columns = ['ID', 'Text'] \n",
    "        df_queries['clean_text'] = df_queries['Text'].apply(clean_for_phase2)\n",
    "        \n",
    "        return df_docs, df_queries\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb1e7e",
   "metadata": {},
   "source": [
    "## Οπτικοποίησης\n",
    "\n",
    "Η κλάση `SemanticVisualizer` είναι υπεύθυνη για τη γραφική αναπαράσταση των διανυσμάτων (embeddings) στον δισδιάστατο χώρο. Επειδή τα διανύσματα έχουν πολλές διαστάσεις (π.χ. 384 για το MiniLM ή 768 για το MPNet), χρησιμοποιούμε την τεχνική **PCA (Principal Component Analysis)** για να μειώσουμε τις διαστάσεις σε 2, ώστε να μπορούμε να τα σχεδιάσουμε.\n",
    "\n",
    "Η κλάση διαθέτει δύο βασικές λειτουργίες:\n",
    "\n",
    "1.  **`plot_single_query` (Semantic Zoom):**\n",
    "    * Εστιάζει σε **μία** συγκεκριμένη ερώτηση και τα Top-K αποτελέσματά της.\n",
    "    * Χρησιμοποιεί χρωματική κλίμακα για να δείξει την ομοιότητα.\n",
    "    * Μας επιτρέπει να δούμε οπτικά πόσο \"κοντά\" είναι τα έγγραφα που ανακτήθηκαν στην ερώτηση που είναι το κόκκινο αστέρι.\n",
    "\n",
    "2.  **`plot_multi_query` (Semantic Universe):**\n",
    "    * Προβάλλει **πολλές ερωτήσεις ταυτόχρονα** μαζί με τα τοπ 20 έγγραφά τους.\n",
    "    * Χρησιμοποιεί διαφορετικά χρώματα για κάθε ερώτηση.\n",
    "    * Βοηθάει να κατανοήσουμε αν οι ερωτήσεις διαχωρίζονται σωστά στον χώρο και αν υπάρχει επικάλυψη θεματολογίας.\n",
    "\n",
    "> Η κλάση δέχεται ως ορίσματα τα ήδη υπολογισμένα αποτελέσματα (`D`, `I`), ώστε να μην χρειάζεται να εκτελεστεί ξανά η διαδικασία της αναζήτησης για κάθε διάγραμμα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0158e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticVisualizer:\n",
    "    def __init__(self, model, df_docs, df_queries, doc_embeddings, D, I):\n",
    "\n",
    "        self.model = model\n",
    "        self.df_docs = df_docs\n",
    "        self.df_queries = df_queries\n",
    "        self.doc_embeddings = doc_embeddings \n",
    "        self.D = D             \n",
    "        self.I = I             \n",
    "        \n",
    "        self.text_col = 'clean_text' if 'clean_text' in df_docs.columns else 'Text'\n",
    "\n",
    "    def plot_single_query(self, query_id, k=50):  \n",
    "        q_idx_list = self.df_queries.index[self.df_queries['ID'] == query_id].tolist()\n",
    "        if not q_idx_list:\n",
    "            print(\"Query not found!\")\n",
    "            return\n",
    "        q_idx = q_idx_list[0]\n",
    "\n",
    "        indices = self.I[q_idx, :k]\n",
    "        scores = self.D[q_idx, :k]\n",
    "        \n",
    "        q_text = self.df_queries.iloc[q_idx][self.text_col]\n",
    "        q_emb = self.model.encode([q_text], normalize_embeddings=True)\n",
    "        \n",
    "        retrieved_doc_embs = self.doc_embeddings[indices]\n",
    "\n",
    "        all_vectors = np.vstack([q_emb, retrieved_doc_embs])\n",
    "        pca = PCA(n_components=2)\n",
    "        coords = pca.fit_transform(all_vectors)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sc = plt.scatter(coords[1:, 0], coords[1:, 1], c=scores, cmap='viridis', s=100, alpha=0.8, label='Documents', edgecolors='k')\n",
    "        plt.colorbar(sc, label='Cosine Similarity')\n",
    "        plt.scatter(coords[0, 0], coords[0, 1], c='red', marker='*', s=400, label=f'Query {query_id}', edgecolors='black', zorder=10)\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            plt.annotate(f\"Rank {i}\", (coords[i, 0], coords[i, 1]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "        plt.title(f\"Semantic Zoom: Query {query_id}\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_multi_query(self, num_queries=10, k=30):\n",
    "        queries_subset = self.df_queries.head(num_queries)\n",
    "        all_vectors = []\n",
    "        plot_data = []\n",
    "        current_idx = 0\n",
    "\n",
    "        for q_idx, row in queries_subset.iterrows():\n",
    "            qid = str(row['ID'])\n",
    "            q_text = row[self.text_col]\n",
    "            \n",
    "            q_emb = self.model.encode([q_text], normalize_embeddings=True)[0]\n",
    "            \n",
    "            indices = self.I[q_idx, :k]\n",
    "            doc_embs = self.doc_embeddings[indices]\n",
    "            \n",
    "            all_vectors.append(q_emb)\n",
    "            all_vectors.extend(doc_embs)\n",
    "            \n",
    "            plot_data.append({\n",
    "                'q_idx': current_idx,\n",
    "                'doc_start': current_idx + 1,\n",
    "                'doc_end': current_idx + 1 + k,\n",
    "                'qid': qid\n",
    "            })\n",
    "            current_idx += (1 + k)\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        coords = pca.fit_transform(np.array(all_vectors))\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        colors = cm.tab10(np.linspace(0, 1, num_queries))\n",
    "\n",
    "        for i, data in enumerate(plot_data):\n",
    "            c = colors[i]\n",
    "            plt.scatter(coords[data['q_idx'], 0], coords[data['q_idx'], 1], color=c, marker='*', s=300, edgecolors='black', label=f\"Q: {data['qid']}\", zorder=10)\n",
    "            \n",
    "            d_start, d_end = data['doc_start'], data['doc_end']\n",
    "            plt.scatter(coords[d_start:d_end, 0], coords[d_start:d_end, 1], color=c, marker='o', s=60, alpha=0.5)\n",
    "            \n",
    "            for d_idx in range(d_start, d_end):\n",
    "                plt.plot([coords[data['q_idx'], 0], coords[d_idx, 0]],\n",
    "                         [coords[data['q_idx'], 1], coords[d_idx, 1]], color=c, alpha=0.15)\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        plt.title(f\"Multi-Query Space (cached results)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11eb4ba",
   "metadata": {},
   "source": [
    "## Αξιολόγηση και Ποιοτικός Έλεγχος\n",
    "\n",
    "Σε αυτή την ενότητα υλοποιούμε κρίσιμες συναρτήσεις για την επαλήθευση της απόδοσης του συστήματος:\n",
    "\n",
    "### 1. `save_and_eval_trec`\n",
    "Αυτή η συνάρτηση αυτοματοποιεί τη διαδικασία της επίσημης αξιολόγησης.\n",
    "* **Εξαγωγή Αποτελεσμάτων:** Μετατρέπει τα αποτελέσματα του FAISS (`I`, `D`) στην τυποποιημένη μορφή **TREC** (`qid Q0 docid rank score runid`) και τα αποθηκεύει σε αρχεία `.txt` για διαφορετικές τιμές του $k$ (π.χ. Top-20, Top-50).\n",
    "* **Υπολογισμός Μετρικών:** Καλεί εξωτερικά το εργαλείο `trec_eval` και υπολογίζει αυτόματα:\n",
    "    * **MAP (Mean Average Precision):** Η συνολική ποιότητα της κατάταξης.\n",
    "    * **P@k (Precision at k):** Ακρίβεια στα πρώτα 5, 10, 15, 20 αποτελέσματα.\n",
    "    * **Recall:** Πόσα από τα σχετικά έγγραφα καταφέραμε να βρούμε συνολικά.\n",
    "    * **Επιστρέφει** τα raw αποτελέσματα (κείμενο) σε ένα λεξικό (`results_dict`), ώστε να μπορούν να χρησιμοποιηθούν από άλλες συναρτήσεις.\n",
    "\n",
    "### 2. `inspect_results_cached`\n",
    "Αυτή η συνάρτηση μας επιτρέπει να εξετάσουμε \"με το μάτι\" τα αποτελέσματα για μια συγκεκριμένη ερώτηση, ώστε να καταλάβουμε *γιατί* το σύστημα πέτυχε ή απέτυχε.\n",
    "* Φορτώνει το αρχείο λύσεων (`qrels.txt`) και συγκρίνει τα ανακτηθέντα έγγραφα με τα σωστά.\n",
    "* Εμφανίζει ένα μικρό τμήμα του κειμένου.\n",
    "\n",
    "### 3. `plot_pr_curve`\n",
    "Αυτή η συνάρτηση μας προσφέρει μια πιο λεπτομερή εικόνα της απόδοσης, παράγουμε την καμπύλη Precision-Recall.\n",
    "Διαβάζουμε τα αποτελέσματα που μόλις αποθηκεύσαμε, τα συγκρίνουμε με το Ground Truth (`qrels.txt`) και παράγουμε την **Micro-Average Precision-Recall Curve**. Αυτό μας δίνει μια πιο ακριβή εικόνα, καθώς λαμβάνει υπόψη κάθε score ομοιότητας ξεχωριστά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f88e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_eval_trec(D, I, df_docs, df_queries, k_list=[20, 30, 50]):\n",
    "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "    for k in k_list:\n",
    "\n",
    "        print(f\"\\n Αποθήκευση αποτελεσμάτων για k={k}...\")\n",
    "        run_id = f\"phase2_results_k{k}\"\n",
    "        output_file = os.path.join(RESULTS_DIR, f\"{run_id}.txt\")\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            for q_idx, row in df_queries.iterrows():\n",
    "                qid = str(row['ID'])\n",
    "                current_indices = I[q_idx, :k]\n",
    "                current_scores = D[q_idx, :k]\n",
    "                for rank, (doc_idx, score) in enumerate(zip(current_indices, current_scores), 1):\n",
    "\n",
    "                    doc_id = str(df_docs.iloc[doc_idx]['ID'])\n",
    "                    f.write(f\"{qid}\\tQ0\\t{doc_id}\\t{rank}\\t{score:.4f}\\t{run_id}\\n\")\n",
    "\n",
    "        if os.path.exists(TREC_EVAL_PATH):\n",
    "            cmd = [TREC_EVAL_PATH, \"-m\", \"map\", \"-m\", \"P.5,10,15,20\", \"-m\", \"recall.5,10,15,20,50\", QRELS_PATH, output_file]\n",
    "            res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            print(f\"--- RESULTS (k={k}) ---\\n{res.stdout}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Not found T-E.\")\n",
    "\n",
    "def plot_pr_curve(k_list=[20, 30, 50]):\n",
    "    qrels_dict = {}\n",
    "    try:\n",
    "        qrels_df = pd.read_csv(QRELS_PATH, sep=r'\\s+', header=None, names=['qid', 'iter', 'docid', 'rel'], dtype=str)\n",
    "        \n",
    "        for _, row in qrels_df.iterrows():\n",
    "            if int(row['rel']) > 0:\n",
    "                qid = str(row['qid'])\n",
    "                docid = str(row['docid'])\n",
    "                if qid not in qrels_dict: qrels_dict[qid] = set()\n",
    "                qrels_dict[qid].add(docid)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Qrels: {e}\")\n",
    "        return\n",
    "\n",
    "    for k in k_list:\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        \n",
    "        results_file = os.path.join(RESULTS_DIR, f\"phase2_results_k{k}.txt\")\n",
    "        \n",
    "        if os.path.exists(results_file):\n",
    "            with open(results_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    qid = parts[0]\n",
    "                    doc_id = parts[2]\n",
    "                    score = float(parts[4])\n",
    "                \n",
    "                    is_rel = 1 if (qid in qrels_dict and doc_id in qrels_dict[qid]) else 0\n",
    "                    \n",
    "                    y_true.append(is_rel)\n",
    "                    y_scores.append(score)\n",
    "            \n",
    "            if len(y_true) > 0:\n",
    "                precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "                pr_auc = auc(recall, precision)\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(recall, precision, color='darkorange', lw=2, \n",
    "                         label=f'PR Curve k={k} (AUC={pr_auc:.4f})')\n",
    "                \n",
    "                plt.title(f'Precision-Recall Curve (Micro-Average, k={k})', fontsize=14, fontweight='bold')\n",
    "                plt.xlabel('Recall', fontsize=12)\n",
    "                plt.ylabel('Precision', fontsize=12)\n",
    "                plt.legend(loc=\"lower left\", fontsize=11)\n",
    "                plt.grid(True, linestyle='--', alpha=0.5)\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                \n",
    "                plt.fill_between(recall, precision, color='darkorange', alpha=0.1)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Warning: No data found for k={k}\")\n",
    "        else:\n",
    "            print(f\"File not found: {results_file}\")\n",
    "\n",
    "def inspect_results_cached(qid, D, I, df_docs, df_queries, k=10):\n",
    "    q_idx_list = df_queries.index[df_queries['ID'] == qid].tolist()\n",
    "    if not q_idx_list: return\n",
    "    q_idx = q_idx_list[0]\n",
    "    \n",
    "    try:\n",
    "        qrels = pd.read_csv(QRELS_PATH, sep=r'\\s+', header=None, names=['qid','0','docid','rel'], dtype=str)\n",
    "        true_docs = set(qrels[(qrels['qid'] == qid) & (qrels['rel'] != '0')]['docid'])\n",
    "    except: true_docs = set()\n",
    "\n",
    "    print(f\"\\nINSPECTION: {qid} (Top-{k})\")\n",
    "    print(f\"Query: {df_queries.iloc[q_idx]['clean_text']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    current_indices = I[q_idx, :k]\n",
    "    current_scores = D[q_idx, :k]\n",
    "    \n",
    "    found = 0\n",
    "    GREEN = \"\\033[92m\" \n",
    "    RED = \"\\033[91m\"   \n",
    "    RESET = \"\\033[0m\" \n",
    "\n",
    "    for rank, (doc_idx, score) in enumerate(zip(current_indices, current_scores), 1):\n",
    "        doc_id = str(df_docs.iloc[doc_idx]['ID'])\n",
    "        text_preview = df_docs.iloc[doc_idx]['clean_text'][:60] + \"...\"\n",
    "        \n",
    "        if doc_id in true_docs:\n",
    "            is_rel = \"OK\"\n",
    "            found += 1\n",
    "            color = GREEN \n",
    "        else:\n",
    "            is_rel = \"NO\"\n",
    "            color = RED   \n",
    "        \n",
    "        print(f\"{rank}. [{color}{is_rel}{RESET}] {doc_id} (Score: {score:.4f}) -> {text_preview}\")\n",
    "    print(f\"Precision@{k}: {found/k:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0a54f",
   "metadata": {},
   "source": [
    "## Ροή Εκτέλεσης\n",
    "\n",
    "Στο τμήμα αυτό ενορχηστρώνεται η συνολική διαδικασία της Σημασιολογικής Αναζήτησης. Η ροή εργασιών (workflow) είναι η εξής:\n",
    "\n",
    "1.  **Φόρτωση Δεδομένων:** Καλούνται τα DataFrames εγγράφων και ερωτήσεων.\n",
    "2.  **Vectorization (Embeddings):**\n",
    "    * Φορτώνεται το προ-εκπαιδευμένο μοντέλο (`SentenceTransformer`).\n",
    "    * Τα κείμενα μετατρέπονται σε διανύσματα.\n",
    "    * **Σημαντικό:** Χρησιμοποιούμε `normalize_embeddings=True`. Αυτό μετατρέπει τα διανύσματα σε μοναδιαία (unit vectors), επιτρέποντας στο Εσωτερικό Γινόμενο να ισοδυναμεί μαθηματικά με την **Ομοιότητα Συνημιτόνου**.\n",
    "3.  **Ευρετηρίαση (Indexing) με FAISS:**\n",
    "    * Δημιουργούμε ευρετήριο `IndexFlatIP`.\n",
    "    * Εισάγουμε τα διανύσματα των εγγράφων στη βάση του FAISS.\n",
    "4.  **Αναζήτηση (Global Search):**\n",
    "    * Εκτελούμε την αναζήτηση **μία φορά** για το μέγιστο βάθος (`MAX_K=50`).\n",
    "5.  **Αξιολόγηση & Οπτικοποίηση:**\n",
    "    * Τα αποτελέσματα στέλνονται στο `trec_eval` για υπολογισμό μετρικών (MAP, Precision, Recall).\n",
    "    * Παράγονται τα γραφήματα PCA (Single & Multi Query) και PR για οπτική επιβεβαίωση της συσταδοποίησης.\n",
    "    * Τέλος, εκτυπώνονται αναλυτικά τα αποτελέσματα για κάθε ερώτηση με χρωματική σήμανση για ποιοτικό έλεγχο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e1fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38831b094ee24462b635c46f9d6de5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_docs, df_queries = load_data()\n",
    "    \n",
    "    if df_docs is not None:\n",
    "\n",
    "        model = SentenceTransformer(MODEL_NAME, device='cpu')\n",
    "        \n",
    "        doc_embeddings = model.encode(df_docs['clean_text'].tolist(), batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "        query_embeddings = model.encode(df_queries['clean_text'].tolist(), show_progress_bar=True, normalize_embeddings=True)\n",
    "        \n",
    "        d = doc_embeddings.shape[1]\n",
    "        index = faiss.IndexFlatIP(d)\n",
    "        index.add(doc_embeddings)\n",
    "\n",
    "        MAX_K = 50 \n",
    "        D, I = index.search(query_embeddings, MAX_K)\n",
    "        \n",
    "        save_and_eval_trec(D, I, df_docs, df_queries, k_list=[20, 30, 50])\n",
    "        plot_pr_curve(k_list=[20, 30, 50])\n",
    "\n",
    "        viz = SemanticVisualizer(model, df_docs, df_queries, doc_embeddings, D, I)\n",
    "        viz.plot_single_query(\"Q01\", k=50)\n",
    "        viz.plot_multi_query(num_queries=10, k=30)\n",
    "        \n",
    "        for qid in df_queries['ID']:\n",
    "            inspect_results_cached(str(qid), D, I, df_docs, df_queries, k=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
