{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586d7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "file_docs = '../data/documents.csv'\n",
    "file_queries = '../data/queries.csv'\n",
    "qrels_file = \"../data/qrels.txt\"\n",
    "trec_eval_path = \"../../trec_eval/trec_eval.exe\"\n",
    "\n",
    "param_grid = {\n",
    "    \"b\": [0.5, 0.6, 0.75, 0.9, 1.0],      \n",
    "    \"k1\": [1.2, 1.6, 2.0, 3.0]\n",
    "}\n",
    "\n",
    "k_targets = [20, 30, 50]\n",
    "\n",
    "print(f\"Status: {es.ping()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6886ba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Εφαρμογή βελτιωμένου καθαρισμού (Prefix & Stopword Removal)...\n",
      "Ολοκληρώθηκε! Τα κείμενα είναι τώρα απαλλαγμένα από boilerplate.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \").replace(\"•\", \" \")\n",
    "    \n",
    "    stop_phrases = [\n",
    "        \"aims to\", \n",
    "        \"is aimed at\",\n",
    "        \"the aim of\",\n",
    "        \"the project objectives will be realised by\",\n",
    "        \"will research and demonstrate\",\n",
    "        \"will research develop and exploit\",\n",
    "        \"brings together research partners\",\n",
    "        \"consortium is composed\",\n",
    "        \"integrates multidisciplinary research teams\",\n",
    "        \"proven track record\",\n",
    "        \"industrial advisory board\",\n",
    "        \"support the eu agenda\",\n",
    "        \"real-world pilots\",\n",
    "        \"market-relevant outcomes\",\n",
    "        \"significant exploitation potential\",\n",
    "        \"the main objective of this project\", \n",
    "        \"this project aims to\", \n",
    "        \"this proposal aims to\", \n",
    "        \"the proposed research\",\n",
    "        \"will be carried out\", \n",
    "        \"state of the art\", \n",
    "        \"beyond the state of the art\",\n",
    "        \"the overall objective\",\n",
    "        \"will be implemented\", \n",
    "        \"will be demonstrated\", \n",
    "        \"will be validated\",\n",
    "        \"proof of concept\", \n",
    "        \"feasibility study\", \n",
    "        \"clinical validation of a\",\n",
    "        \"marie sklodowska-curie\", \"marie curie\", \n",
    "        \"european union\", \"horizon 2020\", \"h2020\", \"fp7\", \n",
    "        \"grant agreement\", \"work package\", \"consortium members\", \n",
    "        \"research and innovation\", \"career development\"\n",
    "    ]\n",
    "    \n",
    "    custom_stopwords = [\n",
    "        \"project\", \"proposal\", \"consortium\", \"partner\", \"deliverable\", \n",
    "        \"workpackage\", \"methodology\" \n",
    "    ]\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    for phrase in stop_phrases:\n",
    "        if phrase in text_lower:\n",
    "            text = re.sub(re.escape(phrase), \" \", text, flags=re.IGNORECASE)\n",
    "            \n",
    "    for word in custom_stopwords:\n",
    "        pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "        text = re.sub(pattern, \" \", text, flags=re.IGNORECASE)\n",
    "            \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "print(\"Εφαρμογή βελτιωμένου καθαρισμού (Prefix & Stopword Removal)...\")\n",
    "\n",
    "\n",
    "df_docs = pd.read_csv(file_docs).dropna(subset=['Text'])\n",
    "df_docs['Text'] = df_docs['Text'].astype(str).apply(preprocess_text)\n",
    "if 'ID' in df_docs.columns: df_docs['ID'] = df_docs['ID'].astype(str)\n",
    "\n",
    "\n",
    "df_queries = pd.read_csv(file_queries)\n",
    "df_queries.columns = df_queries.columns.str.strip()\n",
    "df_queries['Text'] = df_queries['Text'].astype(str).apply(preprocess_text)\n",
    "\n",
    "print(f\"Ολοκληρώθηκε! Τα κείμενα είναι τώρα απαλλαγμένα από boilerplate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6e33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/20] Testing: b=0.5, k1=1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anthi\\AppData\\Local\\Temp\\ipykernel_16160\\1131505958.py:72: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  response = es.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best for k=20: MAP = 0.6707\n",
      "New Best for k=30: MAP = 0.7451\n",
      "New Best for k=50: MAP = 0.7607\n",
      "\n",
      "[2/20] Testing: b=0.5, k1=1.6\n",
      "New Best for k=20: MAP = 0.6952\n",
      "New Best for k=30: MAP = 0.7659\n",
      "New Best for k=50: MAP = 0.7802\n",
      "\n",
      "[3/20] Testing: b=0.5, k1=2.0\n",
      "New Best for k=20: MAP = 0.6967\n",
      "New Best for k=50: MAP = 0.7815\n",
      "\n",
      "[4/20] Testing: b=0.5, k1=3.0\n",
      "\n",
      "[5/20] Testing: b=0.6, k1=1.2\n",
      "\n",
      "[6/20] Testing: b=0.6, k1=1.6\n",
      "New Best for k=20: MAP = 0.7073\n",
      "New Best for k=50: MAP = 0.7843\n",
      "\n",
      "[7/20] Testing: b=0.6, k1=2.0\n",
      "New Best for k=20: MAP = 0.7155\n",
      "New Best for k=30: MAP = 0.7694\n",
      "New Best for k=50: MAP = 0.7880\n",
      "\n",
      "[8/20] Testing: b=0.6, k1=3.0\n",
      "New Best for k=30: MAP = 0.7716\n",
      "New Best for k=50: MAP = 0.7885\n",
      "\n",
      "[9/20] Testing: b=0.75, k1=1.2\n",
      "\n",
      "[10/20] Testing: b=0.75, k1=1.6\n",
      "New Best for k=20: MAP = 0.7283\n",
      "New Best for k=30: MAP = 0.7737\n",
      "New Best for k=50: MAP = 0.7952\n",
      "\n",
      "[11/20] Testing: b=0.75, k1=2.0\n",
      "New Best for k=30: MAP = 0.7795\n",
      "\n",
      "[12/20] Testing: b=0.75, k1=3.0\n",
      "New Best for k=20: MAP = 0.7295\n",
      "New Best for k=30: MAP = 0.7809\n",
      "New Best for k=50: MAP = 0.7984\n",
      "\n",
      "[13/20] Testing: b=0.9, k1=1.2\n",
      "\n",
      "[14/20] Testing: b=0.9, k1=1.6\n",
      "\n",
      "[15/20] Testing: b=0.9, k1=2.0\n",
      "New Best for k=20: MAP = 0.7305\n",
      "\n",
      "[16/20] Testing: b=0.9, k1=3.0\n",
      "New Best for k=20: MAP = 0.7337\n",
      "New Best for k=30: MAP = 0.7840\n",
      "\n",
      "[17/20] Testing: b=1.0, k1=1.2\n",
      "\n",
      "[18/20] Testing: b=1.0, k1=1.6\n",
      "\n",
      "[19/20] Testing: b=1.0, k1=2.0\n",
      "New Best for k=20: MAP = 0.7373\n",
      "New Best for k=30: MAP = 0.7851\n",
      "New Best for k=50: MAP = 0.8039\n",
      "\n",
      "[20/20] Testing: b=1.0, k1=3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_results = {k: {\"map\": 0.0, \"params\": None} for k in k_targets}\n",
    "\n",
    "\n",
    "grid_index_name = \"ir2025_grid_search_temp\"\n",
    "\n",
    "total_combinations = len(param_grid['b']) * len(param_grid['k1'])\n",
    "current_run = 0\n",
    "\n",
    "for b in param_grid['b']:\n",
    "    for k1 in param_grid['k1']:\n",
    "        current_run += 1\n",
    "        print(f\"\\n[{current_run}/{total_combinations}] Testing: b={b}, k1={k1}\")\n",
    "        \n",
    "        if es.indices.exists(index=grid_index_name):\n",
    "            es.indices.delete(index=grid_index_name)\n",
    "            \n",
    "        settings = {\n",
    "            \"settings\": {\n",
    "                \"number_of_shards\": 1,\n",
    "                \"number_of_replicas\": 0,\n",
    "                \"index\": {\n",
    "                    \"similarity\": {\n",
    "                        \"custom_bm25\": { \n",
    "                            \"type\": \"BM25\",\n",
    "                            \"b\": b,\n",
    "                            \"k1\": k1\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"analysis\": {\n",
    "                    \"analyzer\": {\n",
    "                        \"research_analyzer\": {\n",
    "                            \"type\": \"custom\",\n",
    "                            \"tokenizer\": \"standard\",\n",
    "                            \"filter\": [\"lowercase\", \"stop\", \"porter_stem\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"filter\": {\n",
    "                        \"stop\": { \"type\": \"stop\", \"stopwords\": \"_english_\" },\n",
    "                        \"porter_stem\": { \"type\": \"stemmer\", \"language\": \"english\" }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"research_analyzer\",\n",
    "                        \"similarity\": \"custom_bm25\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        es.indices.create(index=grid_index_name, body=settings)\n",
    "        \n",
    "        def generate_docs():\n",
    "            for _, row in df_docs.iterrows():\n",
    "                yield {\n",
    "                    \"_index\": grid_index_name,\n",
    "                    \"_source\": {\"doc_id\": row['ID'], \"text\": row['Text']}\n",
    "                }\n",
    "        bulk(es, generate_docs())\n",
    "        es.indices.refresh(index=grid_index_name)\n",
    "        \n",
    "        for k in k_targets:\n",
    "            results_file = f\"../results/grid_b{b}_k1{k1}_k{k}.txt\"\n",
    "            \n",
    "            with open(results_file, 'w') as f:\n",
    "                for _, row in df_queries.iterrows():\n",
    "                    if not row['Text']: continue\n",
    "                    \n",
    "                    response = es.search(\n",
    "                        index=grid_index_name,\n",
    "                        body={\"query\": {\"match\": {\"text\": row['Text']}}},\n",
    "                        size=k\n",
    "                    )\n",
    "                    \n",
    "                    for rank, hit in enumerate(response['hits']['hits']):\n",
    "                        doc_id = hit['_source']['doc_id']\n",
    "                        score = hit['_score']\n",
    "                        f.write(f\"{row['ID']}\\tQ0\\t{doc_id}\\t{rank+1}\\t{score:.4f}\\tgrid_run\\n\")\n",
    "            \n",
    "            try:\n",
    "                cmd = [trec_eval_path, \"-m\", \"map\", qrels_file, results_file]\n",
    "                res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "                \n",
    "                map_score = float(res.stdout.split()[-1])\n",
    "                \n",
    "                if map_score > best_results[k]['map']:\n",
    "                    best_results[k]['map'] = map_score\n",
    "                    best_results[k]['params'] = (b, k1)\n",
    "                    print(f\"New Best for k={k}: MAP = {map_score:.4f}\")\n",
    "                    \n",
    "                os.remove(results_file)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating k={k}: {e}\")\n",
    "\n",
    "if es.indices.exists(index=grid_index_name):\n",
    "    es.indices.delete(index=grid_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cb62f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ΤΕΛΙΚΑ ΑΠΟΤΕΛΕΣΜΑΤΑ GRID SEARCH (ME PREPROCESSING)\n",
      "============================================================\n",
      "\n",
      "Για k = 20:\n",
      "Best MAP: 0.7373\n",
      "Params:   b = 1.0, k1 = 2.0\n",
      "\n",
      "Για k = 30:\n",
      "Best MAP: 0.7851\n",
      "Params:   b = 1.0, k1 = 2.0\n",
      "\n",
      "Για k = 50:\n",
      "Best MAP: 0.8039\n",
      "Params:   b = 1.0, k1 = 2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ΤΕΛΙΚΑ ΑΠΟΤΕΛΕΣΜΑΤΑ GRID SEARCH (ME PREPROCESSING)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for k in k_targets:\n",
    "    res = best_results[k]\n",
    "    print(f\"\\nΓια k = {k}:\")\n",
    "    print(f\"Best MAP: {res['map']:.4f}\")\n",
    "    print(f\"Params:   b = {res['params'][0]}, k1 = {res['params'][1]}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
